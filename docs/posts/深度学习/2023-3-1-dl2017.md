---
tags:  
    - 深度学习
    - 吴恩达
desc: 吴恩达深度学习入门课程笔记系列
---

# 深度学习入门笔记(一)

:::tip 参考
[Deeplearning.ai深度学习教程中文笔记](https://github.com/fengdu78/deeplearning_ai_books)
:::

## 深度学习引言

### ReLU激活函数
Rectified Linear Unit[^1]

[^1]: rectify:修正


单神经元网络-> 多个单神经元叠加

![](https://cdn.jsdelivr.net/gh/open17/Pic/img/202403011625594.png)

在图上每一个画的小圆圈都可以是ReLU的一部分，也就是指修正线性单元，或者其它稍微非线性的函数

- 输入层和中间层被紧密的连接
- 隐藏单元圆圈，在一个神经网络中，它们每个都从输入的四个特征获得自身输入

神经网络非常擅长计算从x到y的精准映射函数

### 神经网络的监督学习

> 现在的大多数神经网络都离不开监督学习

:::success 扩展
对于图像应用，我们经常在神经网络上使用卷积（Convolutional Neural Network），通常缩写为CNN。对于序列数据，例如音频，有一个时间组件，随着时间的推移，音频被播放出来，所以音频是最自然的表现。作为一维时间序列（两种英文说法one-dimensional time series / temporal sequence）.对于序列数据，经常使用RNN，一种递归神经网络（Recurrent Neural Network），语言，英语和汉语字母表或单词都是逐个出现的，所以语言也是最自然的序列数据，因此更复杂的RNNs版本经常用于这些应用
:::

一个标准的神经网络:
![](https://cdn.jsdelivr.net/gh/open17/Pic/img/202403011632636.png)


一个卷积神经网络的例子:
![](https://cdn.jsdelivr.net/gh/open17/Pic/img/202403011633200.png)


### 结构化数据与非结构化数据

与结构化数据比较[^2]，通常让计算机理解非结构化数据很难

多亏了深度学习和神经网络，计算机现在能更好地解释非结构化数据

神经网络算法对于结构化和非结构化数据都有用处

[^2]: 如数据库

### 为什么兴起

#### 数据量增大
仅仅在过去的20年里对于很多应用，我们便收集到了大量的数据，远超过机器学习算法能够高效发挥它们优势的规模

####  算法方面的创新
例子，sigmoid函数转换到ReLU函数

sigmoid: 梯度接近零的时候，参数会更新的很慢，所以学习的速率也会变的很慢

仅仅通过将Sigmod函数转换成ReLU函数，便能够使得一个叫做梯度下降（gradient descent）的算法运行的更快

![](https://cdn.jsdelivr.net/gh/open17/Pic/img/202403011643390.png)